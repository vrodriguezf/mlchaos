{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_default_export utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "> Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "import numpy as np\n",
    "from fastcore.all import *\n",
    "from fastai.interpret import *\n",
    "from fastai.data.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def df_slicer(df, w, s=1, padding=False, padding_value=0, return_as='ndarray'):\n",
    "    \"Transform a numeric dataframe `df` into slices (np arrays) of `w` \\\n",
    "    rows and the same number of columns than the original dataframe. The \\\n",
    "    distance between each slice is given by the stride `s`. If `padding` is \\\n",
    "    equals to True, the last slices which have less than `w` points are filled \\\n",
    "    with the value marked in the argument `padding_value`. Otherwise, those \\\n",
    "    slices are removed from the result.\"\n",
    "    aux = [df.iloc[x:x+w] for x in range(0, len(df), s)]\n",
    "    if padding:\n",
    "        with_padding = [x.append(pd.DataFrame(\n",
    "            np.full((w - len(x), len(df.columns)), padding_value),\n",
    "            columns=df.columns.values)) if len(x) < w else x for x in aux]\n",
    "    else:\n",
    "        with_padding = [x for x in aux if len(x) == w]\n",
    "    return np.rollaxis(np.dstack([x.values for x in with_padding]), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allow `ClassificationInterpretation.top_losses` to filter by error type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "class ClassificationInterpretationAugmented(ClassificationInterpretation):\n",
    "    def top_losses(self, k=None, largest=True, predicted=None, actual=None):\n",
    "        \"`k` largest(/smallest) losses and indexes, defaulting to all losses (sorted by `largest`).\"\n",
    "        if predicted is None and actual is None:\n",
    "            # Default behaviour\n",
    "            return self.losses.topk(ifnone(k, len(self.losses)), largest=largest)\n",
    "        else:\n",
    "            # Subset losses by the conditions given in predicted and actual arguments\n",
    "            cond_preds = (self.decoded == self.vocab.o2i[predicted]) if predicted else tensor(True)\n",
    "            cond_actuals = (self.targs == self.vocab.o2i[actual]) if actual else tensor(True)\n",
    "            idxs = (cond_preds & cond_actuals).nonzero().squeeze()\n",
    "            loss_subset = self.losses[idxs].topk(ifnone(k, len(idxs)), largest=largest)\n",
    "            # The indices in loss_subset are relative to the object `idxs`. We have to\n",
    "            # return the aboluste idxs with respect to the `self` object.\n",
    "            # TODO: It's returning a pair instead of a topk object\n",
    "            return (loss_subset.values, idxs[loss_subset.indices])\n",
    "\n",
    "\n",
    "    def plot_top_losses(self, k, largest=True, predicted=None,\n",
    "                        actual=None, **kwargs):\n",
    "        losses,idx = self.top_losses(k, largest, predicted, actual)\n",
    "        if not isinstance(self.inputs, tuple): self.inputs = (self.inputs,)\n",
    "        if isinstance(self.inputs[0], torch.Tensor): inps = tuple(o[idx] for o in self.inputs)\n",
    "        else: inps = self.dl.create_batch(self.dl.before_batch([tuple(o[i] for o in self.inputs) for i in idx]))\n",
    "        b = inps + tuple(o[idx] for o in (self.targs if is_listy(self.targs) else (self.targs,)))\n",
    "        x,y,its = self.dl._pre_show_batch(b, max_n=k)\n",
    "        b_out = inps + tuple(o[idx] for o in (self.decoded if is_listy(self.decoded) else (self.decoded,)))\n",
    "        x1,y1,outs = self.dl._pre_show_batch(b_out, max_n=k)\n",
    "        if its is not None:\n",
    "            plot_top_losses(x, y, its, outs.itemgot(slice(len(inps), None)), self.preds[idx], losses,  **kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
